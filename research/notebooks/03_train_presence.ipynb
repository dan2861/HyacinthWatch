{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyM+ZpYz+E805M1p2AbcB2z/"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","from google.colab import auth\n","from google.auth import default\n","import os\n","\n","# Attempt to unmount the drive if it's already mounted and remove the directory\n","try:\n","  drive.flush_and_unmount()\n","except ValueError:\n","  pass # Drive was not mounted, continue\n","\n","# Explicitly remove and recreate the mount point directory\n","if os.path.exists('/content/drive/'):\n","    os.system('rm -rf /content/drive/')\n","os.makedirs('/content/drive/', exist_ok=True)\n","\n","drive.mount('/content/drive/', force_remount=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9E-0qRKbmhFg","executionInfo":{"status":"ok","timestamp":1760227440915,"user_tz":240,"elapsed":16911,"user":{"displayName":"Daniel Yonas","userId":"00860994186254107140"}},"outputId":"9d908f6a-8a13-405e-d7d1-11dc46a338f3"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive not mounted, so nothing to flush and unmount.\n","Mounted at /content/drive/\n"]}]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NN0fJ4Vwj86q","executionInfo":{"status":"ok","timestamp":1760227449169,"user_tz":240,"elapsed":8163,"user":{"displayName":"Daniel Yonas","userId":"00860994186254107140"}},"outputId":"e25fad2a-8099-4ac5-b37e-642171454f72"},"outputs":[{"output_type":"stream","name":"stdout","text":["2603 train, 643 val\n"]}],"source":["import os, pandas as pd, torch, torch.nn as nn, torch.optim as optim\n","from torch.utils.data import Dataset, DataLoader\n","from PIL import Image\n","\n","# paths / hyperparams\n","CSV  = \"/content/drive/MyDrive/HyacinthWatch_workspace/HyacinthWatch_data/processed/metadata.csv\"\n","RUNS = \"/content/drive/MyDrive/HyacinthWatch_workspace/HyacinthWatch_data/runs\"\n","SIZE, BATCH, EPOCHS, LR = 224, 32, 5, 1e-3\n","\n","os.makedirs(RUNS, exist_ok=True)\n","\n","\n","# filter Bangladesh augmented only\n","df = pd.read_csv(CSV)\n","train_df = df.query(\"source=='bangladesh_augmented' and split=='train'\")\n","val_df   = df.query(\"source=='bangladesh_augmented' and split=='val'\")\n","print(len(train_df), \"train,\", len(val_df), \"val\")  # quick sanity"]},{"cell_type":"markdown","source":["Dataset & Loaders"],"metadata":{"id":"VT8DzwBsoDIu"}},{"cell_type":"code","source":["import numpy as np\n","\n","class PresenceDataset(Dataset):\n","    def __init__(self, frame, size=224):\n","        self.df = frame.reset_index(drop=True); self.size = size\n","    def __len__(self): return len(self.df)\n","    def __getitem__(self, i):\n","        r = self.df.iloc[i]\n","        x = Image.open(r.image_path).convert(\"RGB\").resize((self.size,self.size))\n","        x = (np.asarray(x).transpose(2,0,1)/255.0).astype(\"float32\")\n","        y = np.float32(r.has_hyacinth)\n","        return x, y\n","\n","dl_tr = DataLoader(PresenceDataset(train_df, SIZE), batch_size=BATCH, shuffle=True,  num_workers=2)\n","dl_va = DataLoader(PresenceDataset(val_df,   SIZE), batch_size=BATCH*2, shuffle=False, num_workers=2)"],"metadata":{"id":"Is1EP-hPlEol","executionInfo":{"status":"ok","timestamp":1760227449171,"user_tz":240,"elapsed":1,"user":{"displayName":"Daniel Yonas","userId":"00860994186254107140"}}},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":["Model, Loss, Train Loop (MobileNetV2 head)"],"metadata":{"id":"RRU2xyJxoIfK"}},{"cell_type":"code","source":["device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","backbone = torch.hub.load('pytorch/vision:v0.14.1','mobilenet_v2', pretrained=True)\n","backbone.classifier[1] = nn.Linear(backbone.last_channel, 1)\n","model = backbone.to(device)\n","\n","loss_fn = nn.BCEWithLogitsLoss()\n","opt = optim.Adam(model.parameters(), lr=LR)\n","\n","def run_epoch(dl, train=True):\n","    model.train(train)\n","    total = 0.0; n=0\n","    with torch.set_grad_enabled(train):\n","        for xb, yb in dl:\n","            xb = torch.tensor(xb, device=device)\n","            yb = torch.tensor(yb, device=device).float().unsqueeze(1)\n","            if train: opt.zero_grad()\n","            logits = model(xb)\n","            loss = loss_fn(logits, yb)\n","            if train: loss.backward(); opt.step()\n","            total += loss.item()*xb.size(0); n += xb.size(0)\n","    return total/max(n,1)\n","\n","best = 1e9\n","for ep in range(EPOCHS):\n","    tr = run_epoch(dl_tr, True)\n","    va = run_epoch(dl_va, False)\n","    print(f\"epoch {ep+1}: train {tr:.4f}  val {va:.4f}\", flush=True)\n","    if va < best:\n","        best = va\n","        torch.save(model.state_dict(), f\"{RUNS}/presence_mobilenetv2.pt\")\n","print(\"saved best to\", f\"{RUNS}/presence_mobilenetv2.pt\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yj1XNmNOoMX-","executionInfo":{"status":"ok","timestamp":1760214703169,"user_tz":240,"elapsed":1321018,"user":{"displayName":"Daniel Yonas","userId":"00860994186254107140"}},"outputId":"0792dc44-5753-43f6-a872-eccc47330a47"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading: \"https://github.com/pytorch/vision/zipball/v0.14.1\" to /root/.cache/torch/hub/v0.14.1.zip\n"]},{"output_type":"stream","name":"stderr","text":["/root/.cache/torch/hub/pytorch_vision_v0.14.1/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: \n","  warn(f\"Failed to load image Python extension: {e}\")\n","/root/.cache/torch/hub/pytorch_vision_v0.14.1/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","/root/.cache/torch/hub/pytorch_vision_v0.14.1/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V2_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V2_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n"]},{"output_type":"stream","name":"stdout","text":["Downloading: \"https://download.pytorch.org/models/mobilenet_v2-b0353104.pth\" to /root/.cache/torch/hub/checkpoints/mobilenet_v2-b0353104.pth\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 13.6M/13.6M [00:00<00:00, 312MB/s]\n","/tmp/ipython-input-2409567763.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  xb = torch.tensor(xb, device=device)\n","/tmp/ipython-input-2409567763.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  yb = torch.tensor(yb, device=device).float().unsqueeze(1)\n"]},{"output_type":"stream","name":"stdout","text":["epoch 1: train 0.1439  val 0.0761\n","epoch 2: train 0.0622  val 0.0316\n","epoch 3: train 0.0464  val 0.0344\n","epoch 4: train 0.0137  val 0.0180\n","epoch 5: train 0.0230  val 0.1401\n","saved best to /content/drive/MyDrive/HyacinthWatch_workspace/HyacinthWatch_data/runs/presence_mobilenetv2.pt\n"]}]},{"cell_type":"markdown","source":["Quick Metrics (acc, confusion matrix)"],"metadata":{"id":"r_FAGUghoQqw"}},{"cell_type":"code","source":["import torch, numpy as np\n","from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay\n","import matplotlib.pyplot as plt\n","\n","# Load the best model state dictionary\n","model.load_state_dict(torch.load(f\"{RUNS}/presence_mobilenetv2.pt\", map_location=device))\n","model.eval()\n","ys, ps = [], []\n","with torch.no_grad():\n","    for xb, yb in dl_va:\n","        # Ensure xb is a tensor and on the correct device\n","        if not isinstance(xb, torch.Tensor):\n","            xb = torch.tensor(xb, device=device)\n","        else:\n","            xb = xb.to(device)\n","\n","        logits = model(xb)\n","        prob = torch.sigmoid(logits).squeeze(1).cpu().numpy()\n","        ps.extend((prob>0.5).astype(np.uint8).tolist())\n","        ys.extend(yb.cpu().numpy().astype(np.uint8).tolist())\n","\n","\n","# compute confusion matrix\n","cm = confusion_matrix(ys, ps)\n","acc = accuracy_score(ys, ps)\n","\n","disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"Non-Hyacinth\", \"Hyacinth\"])\n","\n","fig, ax = plt.subplots(figsize=(5,4))\n","disp.plot(cmap=\"Greens\", ax=ax)\n","plt.title(f\"Presence Classifier Confusion Matrix\\nAccuracy = {acc*100:.1f}%\")\n","plt.ylabel(\"True Label\")\n","plt.xlabel(\"Predicted Label\")\n","plt.tight_layout()\n","plt.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":216},"id":"rsDNZNmyoTXC","executionInfo":{"status":"error","timestamp":1760227455109,"user_tz":240,"elapsed":1586,"user":{"displayName":"Daniel Yonas","userId":"00860994186254107140"}},"outputId":"d7ef9d71-dda8-4ccc-9ede-70501d60e466"},"execution_count":4,"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'model' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-3737416118.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Load the best model state dictionary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{RUNS}/presence_mobilenetv2.pt\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"]}]}]}